{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_detection_v1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNgvZ86wUR3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload \n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGYMaptFErx8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !sudo apt install tesseract-ocr\n",
        "# !pip install pytesseract\n",
        "# ! pip install vaderSentiment\n",
        "# !pip install flair"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRw4sOxuvAos",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk \n",
        "import string\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "import flair\n",
        "\n",
        "import pytesseract\n",
        "from PIL import Image,ImageOps\n",
        "import numpy as np\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from textblob import TextBlob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uwic8QQVUf4G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "03e8cbb3-b0ea-423c-c439-40159ea1b2df"
      },
      "source": [
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/\"\n",
        "base_dir = '/content/gdrive/My Drive/app/data/Text_Det'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZebbXhm9r7Hd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Method 1 to determine the text on image\n",
        "\n",
        "def GetImageText3(img, thres):\n",
        "  img = Image.open(img).convert(\"L\")\n",
        "  img = ImageOps.invert(img)\n",
        "\n",
        "  threshold = thres\n",
        "  table = []\n",
        "  pixelArray = img.load()\n",
        "  for y in range(img.size[1]):\n",
        "    List = []\n",
        "    \n",
        "    for x in range(img.size[0]):\n",
        "      if pixelArray[x,y] < threshold:\n",
        "        List.append(0)\n",
        "      else:\n",
        "        List.append(255)\n",
        "    table.append(List)\n",
        "\n",
        "  img = Image.fromarray(np.array(table,dtype=\"uint8\")) # load the image from array.\n",
        "  txt = pytesseract.image_to_string(img)\n",
        "  \n",
        "  return (txt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmDzq3zTcvJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Find_Image(img):\n",
        "  \n",
        "  str_final =\"\"\n",
        "\n",
        "  for i in range(10, 50, 10):\n",
        "    txt= GetImageText3(img,i)\n",
        "\n",
        "    txt_len = len(txt)\n",
        "\n",
        "    if (len(txt)>0):\n",
        "      if (len(txt)>len(str_final)):\n",
        "        str_final = txt\n",
        "\n",
        "  return str_final"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W_Od0PP4R6K5",
        "colab": {}
      },
      "source": [
        "#Method 2 to determine the text on image\n",
        "\n",
        "def GetImageText1(img_name):\n",
        "  \n",
        "  str_final =\"\"\n",
        "  found=0\n",
        "\n",
        "  # Load image, grayscale, Gaussian blur, adaptive threshold\n",
        "  image = cv2.imread(img_name)\n",
        "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  blur = cv2.GaussianBlur(gray, (9,9), 0)\n",
        "  thresh = cv2.adaptiveThreshold(blur,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV,11,30)\n",
        "\n",
        "  # Dilate to combine adjacent text contours\n",
        "  kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9,9))\n",
        "  dilate = cv2.dilate(thresh, kernel, iterations=4)\n",
        "\n",
        "  # Find contours, highlight text areas, and extract ROIs\n",
        "  cnts = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
        "\n",
        "\n",
        "  ROI_number = 0\n",
        "  for c in cnts:\n",
        "    area = cv2.contourArea(c)\n",
        "    if area > 10:\n",
        "      found=1\n",
        "      x,y,w,h = cv2.boundingRect(c)\n",
        "      cv2.rectangle(image, (x, y), (x + w, y + h), (36,255,12), 3)\n",
        "      text = image[y:y+h, x:x+w]\n",
        "        \n",
        "  custom_config = r'-l eng --oem 3 --psm 6'\n",
        "\n",
        "  #cv2_imshow( text)\n",
        "  if found!=0:\n",
        "    str_final=pytesseract.image_to_string(text,config=custom_config)\n",
        "\n",
        "  return (str_final)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lY0hmNWxoCK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Method 3 to determine the text on image\n",
        "\n",
        "def GetImageText2(img_name):\n",
        "\n",
        "  str_final =\"\"\n",
        "  found=0\n",
        "\n",
        "  img = cv2.imread(img_name)\n",
        "\n",
        "  # convert to gray\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  # threshold image\n",
        "  thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)[1]\n",
        "\n",
        "  # apply morphology to clean up small white or black regions\n",
        "  kernel = np.ones((5,5), np.uint8)\n",
        "  morph = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
        "  morph = cv2.morphologyEx(morph, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "  # thin region to remove excess black border\n",
        "  kernel = np.ones((3,3), np.uint8)\n",
        "  morph = cv2.morphologyEx(morph, cv2.MORPH_ERODE, kernel)\n",
        "\n",
        "  # find contours\n",
        "  cntrs = cv2.findContours(morph, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  cntrs = cntrs[0] if len(cntrs) == 2 else cntrs[1]\n",
        "\n",
        "  # Contour filtering -- keep largest, vertically oriented object (h/w > 1)\n",
        "  area_thresh = 10\n",
        "  for c in cntrs:\n",
        "    area = cv2.contourArea(c)\n",
        "    x,y,w,h = cv2.boundingRect(c)\n",
        "    aspect = h / w\n",
        "    if area > area_thresh:\n",
        "      found = 1\n",
        "      big_contour = c\n",
        "      area_thresh = area\n",
        "\n",
        " \n",
        "\n",
        "  if(found==1):\n",
        "    x,y,w,h = cv2.boundingRect(big_contour)\n",
        "    text = img[y:y+h, x:x+w]\n",
        "    custom_config = r'-l eng --oem 3 --psm 6'\n",
        "    str_final= pytesseract.image_to_string(text,config=custom_config)\n",
        "\n",
        "  return (str_final)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHlhxeYbqXsD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d8cb6528-9d29-44df-f881-15b32f9b2bf0"
      },
      "source": [
        "_, _, files = next(os.walk(base_dir))\n",
        "file_count = len(files)\n",
        "print(file_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "239\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Cu_NBk7lEeM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_final = pd.DataFrame(columns=['image', 'txt1', 'txt2','txt3'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amjg85iPhFH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i = 0\n",
        "for filename in os.listdir(base_dir):\n",
        "\n",
        "  try:\n",
        "    str1= GetImageText1(os.path.join(base_dir, filename))\n",
        "    str2= GetImageText2(os.path.join(base_dir, filename))\n",
        "    str3= Find_Image(os.path.join(base_dir, filename))\n",
        "    \n",
        "    df_final.loc[i] =[filename,str1,str2,str3]\n",
        "    i=i+1\n",
        "  except Exception as e:\n",
        "    print(filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROt3bBaCBPEB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_final.head(5)\n",
        "df_final_bak= df_final.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Uc5s-Tu05ah",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "182d598d-789b-45bb-8b87-7e515c875047"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tU1xyAm0982Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############## Text Cleanup ###################\n",
        "stopword = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "def remove_punct(text):\n",
        "    text  = \"\".join([char for char in text if char not in string.punctuation])\n",
        "    text = re.sub('[0-9]+', '', text)\n",
        "    return text\n",
        "\n",
        "def tokenization(text):\n",
        "    text = re.split('\\W+', text)\n",
        "    return text\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    text = [word for word in text if word not in stopword]\n",
        "    return text\n",
        " \n",
        "def stemming(text):\n",
        "    text = [ps.stem(word) for word in text]\n",
        "    return text\n",
        "\n",
        "def lemmatizer(text):\n",
        "    text = [wn.lemmatize(word) for word in text]\n",
        "    return text\n",
        "\n",
        "ps = nltk.PorterStemmer()\n",
        "wn = nltk.WordNetLemmatizer()\n",
        "stop = stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hQcMmNLDxmJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_final['final_txt'] = np.select([len(df_final.txt1) > 0 , len(df_final.txt2) > 0], [df_final.txt1, df_final.txt2], default=\"\")\n",
        "df_final['final_txt'] = np.select([len(df_final.final_txt) > 0 , len(df_final.txt3) > 0], [df_final.final_txt, df_final.txt3], default=\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-r2q4DIJ-NyL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_final['final_txt']= df_final['final_txt'].apply(lambda x: remove_punct(x))\n",
        "df_final['final_txt']  = df_final['final_txt'] .apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
        "#df_final['final_txt'] =df_final['final_txt'].apply(lambda x: tokenization(x.lower()))\n",
        "\n",
        "#df_final['final_txt']  =df_final['final_txt'] .apply(lambda x: stemming(x))\n",
        "#df_final['final_txt']  = df_final['final_txt'].apply(lambda x: lemmatizer(x))\n",
        "\n",
        "df_final['final_txt']= df_final['final_txt'].apply(lambda x: re.sub(\"\\s\\s+\" , \" \", x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqKShUx1M0Xr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "analyser = SentimentIntensityAnalyzer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rba7GJqqZUHJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_final[\"Sentiment\"]=\"Random\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBLe_lGROGQb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Find the sentiment of each text found \n",
        "for i,row in df_final.iterrows():\n",
        "\n",
        "  str_final =\"Positive\"\n",
        "\n",
        "  if (len(row['txt1'])>0):\n",
        "    \n",
        "    sent= analyser.polarity_scores(row['txt1'])['compound']\n",
        "  \n",
        "    if (sent>= 0.05):\n",
        "      str_final=\"Positive\"\n",
        "    elif (sent>-0.05 and sent <0.05):\n",
        "      str_final= \"Random\"\n",
        "    else:\n",
        "      str_final= \"Negative\"\n",
        "     \n",
        "    df_final.at[i,'Sentiment'] = str_final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0S3Q_zEc47q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_final1=df_final[[\"image\",\"Sentiment\"]]\n",
        "df_final1.columns = ['Filename', 'Category']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-rfyU_7a5Gd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_final1.to_csv(\"/content/gdrive/My Drive/app/data/Image_out.csv\", index= False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvMubFO9dOyr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "638069a6-2886-41f1-80d0-06da319d9ee8"
      },
      "source": [
        "df_final1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(239, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38_zoYT0dU1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########### Using Flair"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHEX4JcqeMsn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fa88bbf7-83ef-4882-b48f-1a9279155d9e"
      },
      "source": [
        "flair_sentiment = flair.models.TextClassifier.load('en-sentiment')\n",
        "for i,row in df_final.iterrows():\n",
        "\n",
        "  str_final =\"Positive\"\n",
        "\n",
        "  if (len(row['final_txt'])>0):\n",
        "    \n",
        "    s = flair.data.Sentence(row['final_txt'])\n",
        "    flair_sentiment.predict(s)\n",
        "    total_sentiment =str( s.labels)\n",
        "    \n",
        "    if (\"POSITIVE\" in total_sentiment):\n",
        "      str_final=\"Positive\"\n",
        "    elif (\"NEGATIVE\" in total_sentiment):\n",
        "      str_final= \"Negative\"\n",
        "    else:\n",
        "      str_final= \"Random\"\n",
        "     \n",
        "    df_final.at[i,'Sentiment'] = str_final\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-16 14:39:21,153 loading file /root/.flair/models/sentiment-en-mix-distillbert.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwD5uYqwekHr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "22be8bf4-68ab-4def-e92d-29c1755a84d8"
      },
      "source": [
        "df_final.Sentiment.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Random      154\n",
              "Positive     47\n",
              "Negative     38\n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtCvokmW9oYA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "b8d919be-7a64-4bd7-fb8d-177763d1eaf2"
      },
      "source": [
        "#Using Text Blob\n",
        "def detect_sent(text):\n",
        "  str_final=\"Random\"\n",
        "  \n",
        "  pol =TextBlob(text).sentiment.polarity\n",
        " \n",
        "  if (pol>= 0.1):\n",
        "    str_final=\"Positive\"\n",
        "  elif (pol>-0.1 and pol <0.1):\n",
        "      str_final= \"Random\"\n",
        "  else:\n",
        "      str_final= \"Negative\"\n",
        "\n",
        "  return (str_final)\n",
        "df_final['Sentiment'] = df_final.final_txt.apply(detect_sent)\n",
        "df_final.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>txt1</th>\n",
              "      <th>txt2</th>\n",
              "      <th>txt3</th>\n",
              "      <th>final_txt</th>\n",
              "      <th>polarity</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Test2434.jpg</td>\n",
              "      <td></td>\n",
              "      <td>‘NOW. IN THE MANU-SAMMITA IT 1S CLEARLY STATED...</td>\n",
              "      <td>nba hinade wehameni‘lide La com hihi\\nLr Llsmm...</td>\n",
              "      <td></td>\n",
              "      <td>Random</td>\n",
              "      <td>Random</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Test145.jpg</td>\n",
              "      <td></td>\n",
              "      <td>ofl\\na)\\nee</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Random</td>\n",
              "      <td>Random</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Test230.jpg</td>\n",
              "      <td>Top Pro 8 C\\nQuotes</td>\n",
              "      <td>66\\n55\\nTop Pro &amp; Con\\nQuotes</td>\n",
              "      <td>Top Pro &amp; Con\\nQuotes</td>\n",
              "      <td>Top Pro C Quotes</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Test2959.jpg</td>\n",
              "      <td></td>\n",
              "      <td>La\\n,</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Random</td>\n",
              "      <td>Random</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Test109.jpg</td>\n",
              "      <td></td>\n",
              "      <td>&gt;\\n5</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Random</td>\n",
              "      <td>Random</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          image                 txt1  ...  polarity Sentiment\n",
              "0  Test2434.jpg                       ...    Random    Random\n",
              "1   Test145.jpg                       ...    Random    Random\n",
              "2   Test230.jpg  Top Pro 8 C\\nQuotes  ...  Positive  Positive\n",
              "3  Test2959.jpg                       ...    Random    Random\n",
              "4   Test109.jpg                       ...    Random    Random\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQpQ_ZfCFO4s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_final=df_final[[\"image\",\"Sentiment\"]]\n",
        "df_final.columns = ['Filename', 'Category']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nU4L1PYtlWDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_final.to_csv(\"/content/gdrive/My Drive/app/data/text.csv\", index= False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfFtssOgQpZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}